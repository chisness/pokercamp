---
title: "#3 Rock Paper Scissors: Challenge"
sidebar: aipcs24
format:
  html:
    math: true
---
## Challenge A: Rock Paper Scissors (RPS)
Usual RPS rules apply with Rock > Scissors > Paper > Rock with $+1$ payouts for a win, $-1$ payouts for a loss, and $0$ for a tie. 

Rock Paper Scissors was [proposed in 2023 to be a "benchmark for multiagent learning"](https://openreview.net/pdf?id=gQnJ7ODIAx) in a DeepMind paper. 

The paper explains that agents are often measured by (a) average return or (b) robustness against a nemesis agent that tries to minimize the agent's returns. Yet it's important for agents to be able to maximize returns *and* be robust to adversaries. 

Why is RPS a good benchmark?

1. It's a repeated game with sequential decisions

2. Performance is measured against a population of varied skills

### The Competition
You will enter a Rock Paper Scissors bot and the field will be 1/2 student bot submissions and 1/2 our bots that will include: 

- Fixed-percentage bots
- Not-very-sophisticated bots that act based only on the most recent observation
- A single more advanced bot

You will play each other bot once for a 1,000 game match. 

## Challenge B: Paper, Scissors, Maybe Rock (PSMR)
The gameplay works the same as RPS with the following additional rule. 

Each matchup is assigned a probability: 

- $X$ is the probability that $P1$ is not allowed to play Rock
- $Y$ is the probability that $P2$ is not allowed to play Scissors

You will not be told your own or your opponent's percentage. 

### The Competition
You will play one 1,000 game match in duplicate against each opponent. 

| Scenario | Your Role | Probability | Opponent's Role | Probability |
|----------|-----------|-------------|-----------------|-------------|
| Duplicate 1 | $P1$ | $X$ | $P2$ | $Y$ |
| Duplicate 2 | $P2$ | $Y$ | $P1$ | $X$ |

You will submit a PSMR bot and the field will include at least: 

- a bot that tries to play $1/3$ - $1/3$ - $1/3$ or as close as it can
- a bot that plays what would be Nash for it if the opponent were unconstrained
- a bot that is our best attempt to do a reasonable thing, limited by the amount of time we actually decide to spend on it

We aren't intending to say much more about how the $X$ and $Y$ probabilities will be generated, and no your bot should not be communicating with itself between matchups/duplicate matches or phoning home to you. (It should be storing info for itself game-to-game within a matchup, however.)

In the current handout version of `challenge-3-psmr` in `aipc-challenges`, you can practice by configuring the $X$ and $Y$ variables by editing `duplicates.txt`. 

<!-- ### Pre-Challenge Exercises
As pre-challenge exercises, you may want to get a CFR solver running and able to solve:

- Regular unconstrained RPS

- PSMR with ( $X0$, $X1$ ) = ( $1$, $0$ )

The connection of these to the bot-writing portion of the challenge is up to you. -->


<!-- 
### RPS Bot Ideas

1. Look at opponent action 2 moves ago and randomize between that action and the action that beats it 

2. Look at opponent action 2 moves ago and randomize between the other 2 actions

3. [Iocaine Powder](https://web.archive.org/web/20160819141717id_/http://www.ofb.net/~egnor/iocaine.html) 

4. Use online CFR

5. Beat last move

6. Beat last 10 moves

7. If win, do the same thing again. If lose, randomize. 

8. Look at my own history and what opponent will estimate that I'm playing. Beat the thing they will play to beat me. 

9. Use percentages that are fixed/slowly moving

10. Track opponent with +1

11. More soon...

## RPS Academic Research

1. [*Nonparametric Strategy Test*, Sam Ganzfried](https://arxiv.org/abs/2312.10695)

This paper takes Rock Paper Scissors sample data from 500 human players who each played 50 games. It does an experiment to see if (a) they are playing the uniform 1/3 1/3 1/3 strategy and (b) that the actions chosen are independent between games. The paper finds that 61% of players are doing so. 

More soon... -->
<!-- 
Humans are predictably irrational

What he discovered was that the student’s decisions during the game tended towards the Nash Equilibrium, which would be picking rock 1/3 of the time, scissors 1/3 of the time, and paper 1/3 of the time. However, despite the Nash Equilibrium, he noticed a pattern with how the games were played. Winners tended to stick with their same strategy, and losers would move on to another strategy. This would repeat for every time a player lost, which he calls “persistent cyclic flows”.

1. Basics of non-Nash responses

1. Advice on parametrizing opponent strategies

2. Online CFR Minimization won’t cut it here – why? -->