---
title: "#3 Rock Paper Scissors: Challenge"
sidebar: aipcs24
format:
  html:
    math: true
---
## The Challenge

Rock Paper Scissors was [proposed in 2023 to be a "benchmark for multiagent learning"](https://openreview.net/pdf?id=gQnJ7ODIAx) in a paper written primarily by DeepMind. 

The paper explains that agents are often measured by (a) average return or (b) robustness against a nemesis agent that tries to minimize the agent's returns. Yet it's important for agents to be able to maximize returns *and* be robust to adversaries. 

Why is RPS a good benchmark?

1. It's a repeated game with sequential decisions

2. Performance is measured against a population of varied skills

This week's challenge is a Rock Paper Scissors tournament.  

### RPS Bot Ideas

1. Look at opponent action 2 moves ago and randomize between that action and the action that beats it 

2. Look at opponent action 2 moves ago and randomize between the other 2 actions

3. [Iocaine Powder](https://web.archive.org/web/20160819141717id_/http://www.ofb.net/~egnor/iocaine.html) 

4. Use online CFR

5. Beat last move

6. Beat last 10 moves

7. If win, do the same thing again. If lose, randomize. 

8. Look at my own history and what opponent will estimate that I'm playing. Beat the thing they will play to beat me. 

9. Use percentages that are fixed/slowly moving

10. Track opponent with +1

11. More soon...

## RPS Academic Research

1. [*Nonparametric Strategy Test*, Sam Ganzfried](https://arxiv.org/abs/2312.10695)

This paper takes Rock Paper Scissors sample data from 500 human players who each played 50 games. It does an experiment to see if (a) they are playing the uniform 1/3 1/3 1/3 strategy and (b) that the actions chosen are independent between games. The paper finds that 61% of players are doing so. 

More soon...
<!-- 
Humans are predictably irrational

What he discovered was that the student’s decisions during the game tended towards the Nash Equilibrium, which would be picking rock 1/3 of the time, scissors 1/3 of the time, and paper 1/3 of the time. However, despite the Nash Equilibrium, he noticed a pattern with how the games were played. Winners tended to stick with their same strategy, and losers would move on to another strategy. This would repeat for every time a player lost, which he calls “persistent cyclic flows”.

1. Basics of non-Nash responses

1. Advice on parametrizing opponent strategies

2. Online CFR Minimization won’t cut it here – why? -->